<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><title>Ampere Gets HBM2E Memory Upgrade - PulseVibe</title><meta name=description content="Kicking off a very virtual version of the SC20 supercomputing show, NVIDIA this morning is announcing a new version of their flagship A100 accelerator. Barely launched 6 months ago, NVIDIA is preparing to release an updated version of the GPU-based accelerator with 80 gigabytes of HBM2e memory, doubling the capacity of the initial version of"><meta name=author content="Some Person"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"PulseVibe","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/nvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html","name":"Ampere gets hbm2 e memory upgrade"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Larita Shotwell"},"headline":"Ampere Gets HBM2E Memory Upgrade","description":"Kicking off a very virtual version of the SC20 supercomputing show, NVIDIA this morning is announcing a new version of their flagship A100 accelerator. Barely launched 6 months ago, NVIDIA is preparing to release an updated version of the GPU-based accelerator with 80 gigabytes of HBM2e memory, doubling the capacity of the initial version of","inLanguage":"en","wordCount":1217,"datePublished":"2024-07-17T00:00:00","dateModified":"2024-07-17T00:00:00","image":"\/img\/avatar-icon.png","keywords":[""],"mainEntityOfPage":"\/nvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/img\/avatar-icon.png","height":60,"width":60}}}</script><meta property="og:title" content="Ampere Gets HBM2E Memory Upgrade"><meta property="og:description" content="Kicking off a very virtual version of the SC20 supercomputing show, NVIDIA this morning is announcing a new version of their flagship A100 accelerator. Barely launched 6 months ago, NVIDIA is preparing to release an updated version of the GPU-based accelerator with 80 gigabytes of HBM2e memory, doubling the capacity of the initial version of"><meta property="og:image" content="/img/avatar-icon.png"><meta property="og:url" content="/nvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html"><meta property="og:type" content="website"><meta property="og:site_name" content="PulseVibe"><meta name=twitter:title content="Ampere Gets HBM2E Memory Upgrade"><meta name=twitter:description content="Kicking off a very virtual version of the SC20 supercomputing show, NVIDIA this morning is announcing a new version of their flagship A100 accelerator. Barely launched 6 months ago, NVIDIA is …"><meta name=twitter:image content="/img/avatar-icon.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@username"><meta name=twitter:creator content="@username"><link href=./img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.98.0"><link rel=alternate href=./index.xml type=application/rss+xml title=PulseVibe><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/highlight.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Ampere Gets HBM2E Memory Upgrade</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on July 17, 2024
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;6&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;1217&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Larita Shotwell</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>Kicking off a very virtual version of the SC20 supercomputing show, NVIDIA this morning is announcing a new version of their flagship A100 accelerator. Barely launched 6 months ago, NVIDIA is preparing to release an updated version of the GPU-based accelerator with 80 gigabytes of HBM2e memory, doubling the capacity of the initial version of the accelerator. And as an added kick, NVIDIA is dialing up the memory clockspeeds as well, bringing the 80GB version of the A100 to 3.2Gbps/pin, or just over 2TB/second of memory bandwidth in total.</p><p>The 80GB version of the A100 will continue to be sold alongside the 40GB version – which NVIDIA is now calling the A100 40GB – and it is being primarily aimed at customers with supersized AI data sets. Which at face value may sound a bit obvious, but with deep learning workloads in particular, memory capacity can be a strongly bounding factor when working with particularly large datasets. So an accelerator that’s large enough to keep an entire model in local memory can potentially be significantly faster than one that has to frequently go off-chip to swap data.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=7><tr class=tgrey readability=2><td align=center colspan=6>NVIDIA Accelerator Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>A100 (80GB)</td><td align=center valign=middle width=126>A100 (40GB)</td><td align=center valign=middle width=126>V100</td></tr><tr><td class=tlgrey>FP32 CUDA Cores</td><td align=center valign=middle>6912</td><td align=center valign=middle>6912</td><td align=center valign=middle>5120</td></tr><tr><td class=tlgrey>Boost Clock</td><td align=center valign=middle>1.41GHz</td><td align=center valign=middle>1.41GHz</td><td align=center valign=middle>1530MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>3.2Gbps HBM2e</td><td align=center valign=middle>2.4Gbps HBM2</td><td align=center valign=middle>1.75Gbps HBM2</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>5120-bit</td><td align=center valign=middle>5120-bit</td><td align=center valign=middle>4096-bit</td></tr><tr><td class=tlgrey>Memory Bandwidth</td><td align=center valign=middle>2.0TB/sec</td><td align=center valign=middle>1.6TB/sec</td><td align=center valign=middle>900GB/sec</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>80GB</td><td align=center valign=middle>40GB</td><td align=center valign=middle>16GB/32GB</td></tr><tr><td class=tlgrey>Single Precision</td><td align=center valign=middle>19.5 TFLOPs</td><td align=center valign=middle>19.5 TFLOPs</td><td align=center valign=middle>15.7 TFLOPs</td></tr><tr readability=6><td class=tlgrey>Double Precision</td><td align=center valign=middle>9.7 TFLOPs<br>(1/2 FP32 rate)</td><td align=center valign=middle>9.7 TFLOPs<br>(1/2 FP32 rate)</td><td align=center valign=middle>7.8 TFLOPs<br>(1/2 FP32 rate)</td></tr><tr><td class=tlgrey>INT8 Tensor</td><td align=center valign=middle>624 TOPs</td><td align=center valign=middle>624 TOPs</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>FP16 Tensor</td><td align=center valign=middle>312 TFLOPs</td><td align=center valign=middle>312 TFLOPs</td><td align=center valign=middle>125 TFLOPs</td></tr><tr><td class=tlgrey>TF32 Tensor</td><td align=center valign=middle>156 TFLOPs</td><td align=center valign=middle>156 TFLOPs</td><td align=center valign=middle>N/A</td></tr><tr readability=6><td class=tlgrey>Interconnect</td><td align=center valign=middle>NVLink 3<br>12 Links (600GB/sec)</td><td align=center valign=middle>NVLink 3<br>12 Links (600GB/sec)</td><td align=center valign=middle>NVLink 2<br>6 Links (300GB/sec)</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GA100<br>(826mm2)</td><td align=center valign=middle>GA100<br>(826mm2)</td><td align=center valign=middle>GV100<br>(815mm2)</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>54.2B</td><td align=center valign=middle>54.2B</td><td align=center valign=middle>21.1B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>400W</td><td align=center valign=middle>400W</td><td align=center valign=middle>300W/350W</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 7N</td><td align=center valign=middle>TSMC 7N</td><td align=center valign=middle>TSMC 12nm FFN</td></tr><tr><td class=tlgrey>Interface</td><td align=center valign=middle>SXM4</td><td align=center valign=middle>SXM4</td><td align=center valign=middle>SXM2/SXM3</td></tr><tr><td class=tlgrey>Architecture</td><td align=center valign=middle>Ampere</td><td align=center valign=middle>Ampere</td><td align=center valign=middle>Volta</td></tr></tbody></table><p>Diving right into the specs, the only difference between the 40GB and 80GB versions of the A100 will be memory capacity and memory bandwidth. Both models are shipping using a mostly-enabled GA100 GPU with 108 active SMs and a boost clock of 1.41GHz. Similarly, the TDPs between the two models remain unchanged as well. So for pure, on-paper compute throughput, there’s no difference between the accelerators.</p><p>Instead, the improvements for the A100 come down to its memory capacity and its greater memory bandwidth. When the original A100 back in May, NVIDIA equipped it with six 8GB stacks of HBM2 memory, with one of those stacks disabled for yield reasons. This left the original A100 with 40GB of memory and just shy of 1.6TB/second of memory bandwidth.</p><p>For the newer A100 80GB, NVIDIA is keeping the same configuration of 5-out-of-6 memory stacks enabled, however the memory itself has been replaced with newer HBM2E memory. HBM2E is the informal name given to the most recent update to the HBM2 memory standard, which back in February of this year defined a new maximum memory speed of 3.2Gbps/pin. Coupled with that frequency improvement, manufacturing improvements have also allowed memory manufacturers to double the capacity of the memory, going from 1GB/die to 2GB/die. The net result being that HBM2E offers both greater capacities as well as greater bandwidths, two things which NVIDIA is taking advantage of here.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/16250/SK_hynix_HBM2E_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>With 5 active stacks of 16GB, 8-Hi memory, the updated A100 gets a total of 80GB of memory. Which, running at 3.2Gbps/pin, works out to just over 2TB/sec of memory bandwidth for the accelerator, a 25% increase over the 40GB version. This means that not only does the 80GB accelerator offer more local storage, but rare for a larger capacity model, it also offers some extra memory bandwidth to go with it. That means that in memory bandwidth-bound workloads the 80GB version should be faster than the 40GB version even without using its extra memory capacity.</p><p>Being able to offer a version of the A100 with more memory bandwidth seems to largely be an artifact of manufacturing rather than something planned by NVIDIA – Samsung and SK Hynix only finally started mass production of HBM2E a bit earlier this year – but none the less it’s sure to be a welcome one.</p><p>Otherwise, as mentioned earlier, the additional memory won’t be changing the TDP parameters of the A100. So the A100 remains a 400 Watt part, and nominally, the 80GB version should be a bit more power efficient since it offers more performance inside the same TDP.</p><p>Meanwhile, NVIDIA has also confirmed that the greater memory capacity of the 80GB model will also be available to Multi-Instance GPU (MIG) users. The A100 still has a hardware limitation of 7 instances, so equal-sized instances can now have up to 10GB of dedicated memory each.</p><p>As far as performance is concerned, NVIDIA is throwing out a few numbers comparing the two versions of the A100. It’s actually a bit surprising that they’re talking up the 80GB version quite so much, as NVIDIA is going to continue selling the 40GB version. But with the A100 80GB likely to cost a leg (NVIDIA <a href=#>already bought the Arm</a>), no doubt there’s still a market for both.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/16250/NV-SC20_13_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Finally, as with the launch of the original A100 earlier this year, NVIDIA’s immediate focus with the A100 80GB is on HGX and DGX configurations. The mezzanine form factor accelerator is designed to be installed in multi-GPU systems, so that is how NVIDIA is selling it: as part of an HGX carrier board with either 4 or 8 of the GPUs installed. For customers that need individual A100s, NVIDIA is continuing to offer the PCIe A100, though not in an 80GB configuration (at least, not yet).</p><p>Along with making the A100 80GB available to HGX customers, NVIDIA is also launching some new DGX hardware today as well. At the high-end, they’re offering a version of the DGX A100 with the new accelerators, which they’ll be calling the DGX A100 640GB. This new DGX A100 also features twice as much DRAM and storage as its predecessor, doubling the original in more than one way.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/16250/NV-SC20_16_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Meanwhile NVIDIA is launching a smaller, workstation version of the DGX A100, which they are calling the DGX Station A100. The successor to the original, Volta-based DGX Station, the DGX Station A100 is essentially half of a DGX A100, with 4 A100 accelerators and a single AMD EPYC processor. NVIDIA’s press pre-briefing didn’t mention total power consumption, but I’ve been told that it runs off of a standard wall socket, far less than the 6.5kW of the DGX A100.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/16250/NV-SC20_21_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>NVIDIA is also noting that the DGX Station uses a <strong>refrigerant</strong> cooling system, meaning that they are using sub-ambient cooling (unlike the original DGX Station, which was simply water cooled). NVIDIA is promising that despite this, the DGX Station A100 is whisper quiet, so it will be interesting to see how much of that is true given the usual noise issues involved in attaching a compressor to a computer cooling loop.</p><p>Both of the new DGX systems as in production now. According to NVIDIA, the systems are already being used for some of their previously-announced supercomputing installations, such as the Cambridge-1 system. Otherwise commercial availability will start in January, with wider availability in February.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH53fpRpZqeumZm2onnAp6WorZ6YsrR5wGpnaWVoZbSjecCmp56qlWK0psDSZp%2BbpWKaeq6xzKipsmWlpbSzrcOe</p><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html&text=Ampere%20Gets%20HBM2E%20Memory%20Upgrade&via=username" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html&title=Ampere%20Gets%20HBM2E%20Memory%20Upgrade" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html&title=Ampere%20Gets%20HBM2E%20Memory%20Upgrade" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html&title=Ampere%20Gets%20HBM2E%20Memory%20Upgrade" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=%2fnvidia-announces-a100-80gb-ampere-gets-hbm2e-memory-upgrade.html&description=Ampere%20Gets%20HBM2E%20Memory%20Upgrade" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section></article><ul class="pager blog-pager"><li class=previous><a href=./live-updates-jake-paul-v-tommy-fury.html data-toggle=tooltip data-placement=top title="Boxing: Tommy Fury defeats Jake Paul - A humbling experience!">&larr; Previous Post</a></li><li class=next><a href=./who-is-ashley-alvano-lamelo-balls-ex-girlfriend-wiki-bio-age-ethnicity-524823-html.html data-toggle=tooltip data-placement=top title="Who is Ashley Alvano? LaMelo Balls ex-girlfriend Wiki Bio, age, ethnicity">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">All rights reserved
&nbsp;&bull;&nbsp;&copy;
2024
&nbsp;&bull;&nbsp;
<a href=./>PulseVibe</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.98.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/main.js></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://assets.cdnweb.info/hugo/bh/js/load-photoswipe.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>